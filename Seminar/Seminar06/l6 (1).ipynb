{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4IgnCZuOs4Fk"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-9AAwHnPr7od"
      },
      "outputs": [],
      "source": [
        "# import zipfile\n",
        "\n",
        "# data_r = zipfile.ZipFile('train.zip', 'r')\n",
        "# data_r.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QNsrrl6VsU_F"
      },
      "outputs": [],
      "source": [
        "# data_r = zipfile.ZipFile('test.zip', 'r')\n",
        "# data_r.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SISIsfkxs5l7"
      },
      "outputs": [],
      "source": [
        "def download_data(path):\n",
        "  data = []\n",
        "  for path_image in sorted(os.listdir(path=path)):\n",
        "    image = Image.open(path + path_image) #Открываем изображение.\n",
        "    data.append(np.array(image)) #Загружаем пиксели.\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "aVma1xbgs2jF"
      },
      "outputs": [],
      "source": [
        "X_train = download_data(r\"train/images/\")\n",
        "Y_train = download_data(r\"train/masks/\")\n",
        "X_test = download_data(r\"test/images/\")\n",
        "Y_test = download_data(r\"test/masks/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "X_ayb_KzU-sY"
      },
      "outputs": [],
      "source": [
        "def resize(input_image, input_mask):\n",
        "   input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "   input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "   return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K4OM3WxRVBCF"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = resize(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "X8Tl2Ee4VH9l"
      },
      "outputs": [],
      "source": [
        "X_test, Y_test = resize(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "5fOK8rmVt0ak",
        "outputId": "75649d54-0e0c-4e82-86e8-d3faa9f4cddb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 128, 3), dtype=int32, numpy=\n",
              "array([[[238, 241, 246],\n",
              "        [185, 190, 196],\n",
              "        [249, 255, 255],\n",
              "        ...,\n",
              "        [178, 177, 185],\n",
              "        [220, 219, 225],\n",
              "        [235, 237, 250]],\n",
              "\n",
              "       [[254, 255, 255],\n",
              "        [252, 255, 255],\n",
              "        [250, 251, 253],\n",
              "        ...,\n",
              "        [213, 209, 223],\n",
              "        [199, 192, 199],\n",
              "        [152, 145, 152]],\n",
              "\n",
              "       [[194, 194, 196],\n",
              "        [239, 238, 243],\n",
              "        [253, 254, 255],\n",
              "        ...,\n",
              "        [ 96,  88, 101],\n",
              "        [157, 142, 149],\n",
              "        [148, 132, 133]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[213, 207, 217],\n",
              "        [238, 233, 239],\n",
              "        [211, 208, 219],\n",
              "        ...,\n",
              "        [247, 240, 234],\n",
              "        [218, 211, 203],\n",
              "        [241, 234, 224]],\n",
              "\n",
              "       [[231, 225, 235],\n",
              "        [166, 161, 167],\n",
              "        [211, 208, 219],\n",
              "        ...,\n",
              "        [255, 253, 250],\n",
              "        [237, 230, 222],\n",
              "        [223, 216, 208]],\n",
              "\n",
              "       [[246, 240, 250],\n",
              "        [198, 191, 198],\n",
              "        [199, 197, 208],\n",
              "        ...,\n",
              "        [240, 237, 230],\n",
              "        [249, 238, 232],\n",
              "        [255, 253, 243]]])>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrG-ykmIuOcj",
        "outputId": "33c47cf2-ad24-4014-a890-d4b4184d77e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXQpzyZt6Ui",
        "outputId": "599cdd4b-b159-4092-a3ec-ed64958f4ae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcmg1WQuTIi",
        "outputId": "12985c79-0d80-422c-e911-f69be60e3bd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI-7mKvJuixR",
        "outputId": "4105938f-2c23-4195-aa30-058272436cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([132,  41, 246, 255])>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMeBQA_suYnq",
        "outputId": "85185bf6-0107-426f-b3a6-8aaeb8ad71ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KC2UWCMGuwz4"
      },
      "outputs": [],
      "source": [
        "palette = {0 : (60, 16, 152), # Building\n",
        "        1 : (132, 41, 246), # Land\n",
        "        2 : (110, 193, 228), # Road\n",
        "        3 : (254, 221, 58), # Vegetation\n",
        "        4 : (226, 169, 41), # Water\n",
        "        5 : (155, 155, 155)} # Unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XJGCusxYvIOi"
      },
      "outputs": [],
      "source": [
        "invert_palette = {v: k for k, v in palette.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "u2xjpP2VvUiY"
      },
      "outputs": [],
      "source": [
        "# сегментация нейронной сети в RGB изображение\n",
        "def convert_to_color(arr_2d, palette=palette):\n",
        "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
        "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = arr_2d == c\n",
        "        arr_3d[m] = i\n",
        "\n",
        "    return arr_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7uyEDYdTv81I"
      },
      "outputs": [],
      "source": [
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8) # принадлежность каждого пикселя классу\n",
        "    min_distance = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.float32)+1000 # расстояние до ближайшего класса для пикселей\n",
        "    for c, i in palette.items():\n",
        "      distance = np.sum((arr_3d - np.array(c).reshape(1, 1, 3))**2, axis=-1)**(1/2) # ищем расстояние для каждого пикселя до проверяемого класса по евклиду рас-ие\n",
        "      condition = min_distance > distance # поиск элементов меньше min_distance\n",
        "      min_distance[condition] = distance[condition] # замена дистанции найденных элементов\n",
        "      arr_2d[condition] = i # замена класса найденных элементов\n",
        "\n",
        "    for c, i in palette.items():\n",
        "      m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "      arr_2d[m] = i\n",
        "\n",
        "    arr_2d = arr_2d.tolist()\n",
        "    for i in range(len(arr_2d)):\n",
        "      for j in range(len(arr_2d[0])):\n",
        "        label = [0, 0, 0, 0, 0, 0]\n",
        "        label[arr_2d[i][j]] = 1\n",
        "        arr_2d[i][j] = label\n",
        "    arr_2d = np.array(arr_2d)\n",
        "\n",
        "    return arr_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QRH5wFPIxysn"
      },
      "outputs": [],
      "source": [
        "X_train_pred = np.array(X_train).reshape([7, 128, 128, 3])/255\n",
        "X_test_pred = np.array(X_test).reshape([2, 128, 128, 3])/255\n",
        "Y_train_pred = []\n",
        "for i in range(len(Y_train)):\n",
        "  Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3]))\n",
        "Y_train_pred = np.array(Y_train_pred)\n",
        "Y_test_pred = []\n",
        "for i in range(len(Y_test)):\n",
        "  Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3]))\n",
        "Y_test_pred = np.array(Y_test_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "S6xEqOpzyK4m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import *\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yw4chFWMT5JY"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "71aa1kS9UdpV"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "6-0SlpZRT9JP"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FVTEl4lXUG_A"
      },
      "outputs": [],
      "source": [
        "def build_unet_model():\n",
        "   # inputs\n",
        "   inputs = layers.Input(shape=(128,128,3))\n",
        "   # encoder: contracting path - downsample\n",
        "   # 1 - downsample\n",
        "   f1, p1 = downsample_block(inputs, 64)\n",
        "   # 2 - downsample\n",
        "   f2, p2 = downsample_block(p1, 128)\n",
        "   # 3 - downsample\n",
        "   f3, p3 = downsample_block(p2, 256)\n",
        "   # 4 - downsample\n",
        "   f4, p4 = downsample_block(p3, 512)\n",
        "   # 5 - bottleneck\n",
        "   bottleneck = double_conv_block(p4, 1024)\n",
        "   # decoder: expanding path - upsample\n",
        "   # 6 - upsample\n",
        "   u6 = upsample_block(bottleneck, f4, 512)\n",
        "   # 7 - upsample\n",
        "   u7 = upsample_block(u6, f3, 256)\n",
        "   # 8 - upsample\n",
        "   u8 = upsample_block(u7, f2, 128)\n",
        "   # 9 - upsample\n",
        "   u9 = upsample_block(u8, f1, 64)\n",
        "   # outputs\n",
        "   outputs = layers.Conv2D(6, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "   # unet model with Keras Functional API\n",
        "   unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "   return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Z3otCMTXUVsr"
      },
      "outputs": [],
      "source": [
        "unet_model = build_unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bR8a8e6KVh86"
      },
      "outputs": [],
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuxCsFsVlyZ",
        "outputId": "0cf5ddd9-2c74-4dc0-fff2-dffd166aab5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 15s 15s/step - loss: 2.7064 - accuracy: 0.0962 - val_loss: 1.3499 - val_accuracy: 0.6048\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 2.1608 - accuracy: 0.6259 - val_loss: 1.2493 - val_accuracy: 0.6046\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.1819 - accuracy: 0.6250 - val_loss: 1.2207 - val_accuracy: 0.6051\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.1603 - accuracy: 0.6270 - val_loss: 1.1515 - val_accuracy: 0.6051\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.1007 - accuracy: 0.6272 - val_loss: 1.0876 - val_accuracy: 0.6051\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.0535 - accuracy: 0.6273 - val_loss: 1.0606 - val_accuracy: 0.6051\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.0447 - accuracy: 0.6273 - val_loss: 1.0600 - val_accuracy: 0.6051\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 8s 8s/step - loss: 1.0601 - accuracy: 0.6272 - val_loss: 1.0501 - val_accuracy: 0.6051\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.0578 - accuracy: 0.6273 - val_loss: 1.0311 - val_accuracy: 0.6051\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 7s 7s/step - loss: 1.0380 - accuracy: 0.6272 - val_loss: 1.0239 - val_accuracy: 0.6051\n",
            "CPU times: total: 7min 51s\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = unet_model.fit(X_train_pred, Y_train_pred,  epochs=10, validation_data = (X_test_pred, Y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "K4RZng-j1lSx"
      },
      "outputs": [],
      "source": [
        "from keras.losses import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "fa1P0qSr1uAI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "Gip9dYsNBDm_",
        "outputId": "fc3961ed-f85f-43f2-9591-5ca573a67190"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Layer \"U-Net\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=796>, <tf.Tensor: shape=(), dtype=int32, numpy=644>]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43munet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m796\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m644\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\GitTest\\Введение в нейронные сети\\Introduction-to-HC\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32md:\\GitTest\\Введение в нейронные сети\\Introduction-to-HC\\.venv\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py:219\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs to a layer should be tensors. Got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) as input for layer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(input_spec):\n\u001b[1;32m--> 219\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m expects \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(input_spec)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input(s),\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but it received \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(inputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m input tensors. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minputs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m     )\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_index, (x, spec) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(inputs, input_spec)):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[1;31mValueError\u001b[0m: Layer \"U-Net\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor: shape=(), dtype=int32, numpy=796>, <tf.Tensor: shape=(), dtype=int32, numpy=644>]"
          ]
        }
      ],
      "source": [
        "model = unet_model((796,644), 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "yAQmdfxZ1sLz"
      },
      "outputs": [],
      "source": [
        "#Функция для подсчёта DICE коэффициента\n",
        "def dice_coef(y_pred, y_true):\n",
        "    y_pred = tf.unstack(y_pred, axis=3)\n",
        "    y_true = tf.unstack(y_true, axis=3)\n",
        "    dice_summ = 0\n",
        "\n",
        "    for i, (a_y_pred, b_y_true) in enumerate(zip(y_pred, y_true)):\n",
        "        dice_calculate = (2 * tf.math.reduce_sum(a_y_pred * b_y_true) + 1) /\\\n",
        "        (tf.math.reduce_sum(a_y_pred + b_y_true) + 1)\n",
        "\n",
        "        dice_summ += dice_calculate\n",
        "    avg_dice = dice_summ/CLASSES\n",
        "    return avg_dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "L9WoQKnD1bRr"
      },
      "outputs": [],
      "source": [
        "#Функция для подсчета DICE loss\n",
        "def dice_loss(y_pred, y_true):\n",
        "    d_loss = 1 - dice_coef(y_pred, y_true)\n",
        "    return d_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "j9lqcvoYzTAE"
      },
      "outputs": [],
      "source": [
        "# Binary crossentropy + 0.25 * DICE\n",
        "def dice_bce_loss(y_pred, y_true):\n",
        "    total_loss = 0.25 * dice_loss(y_pred, y_true) + keras.losses.binary_crossentropy(y_pred, y_true)\n",
        "    return total_loss"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
