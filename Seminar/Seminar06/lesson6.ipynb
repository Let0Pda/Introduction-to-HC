{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4IgnCZuOs4Fk"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-9AAwHnPr7od"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "data_r = zipfile.ZipFile('train.zip', 'r')\n",
        "data_r.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QNsrrl6VsU_F"
      },
      "outputs": [],
      "source": [
        "data_r = zipfile.ZipFile('test.zip', 'r')\n",
        "data_r.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SISIsfkxs5l7"
      },
      "outputs": [],
      "source": [
        "def download_data(path):\n",
        "  data = []\n",
        "  for path_image in sorted(os.listdir(path=path)):\n",
        "    image = Image.open(path + path_image) #Открываем изображение.\n",
        "    data.append(np.array(image)) #Загружаем пиксели.\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aVma1xbgs2jF"
      },
      "outputs": [],
      "source": [
        "X_train = download_data(r\"train/images/\")\n",
        "Y_train = download_data(r\"train/masks/\")\n",
        "X_test = download_data(r\"test/images/\")\n",
        "Y_test = download_data(r\"test/masks/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "5fOK8rmVt0ak",
        "outputId": "55c64b19-34af-40e1-819b-bc0bbe86fa6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[177, 181, 184],\n",
              "        [205, 209, 212],\n",
              "        [219, 222, 227],\n",
              "        ...,\n",
              "        [226, 229, 244],\n",
              "        [230, 233, 250],\n",
              "        [243, 246, 255]],\n",
              "\n",
              "       [[217, 221, 224],\n",
              "        [244, 248, 251],\n",
              "        [252, 255, 255],\n",
              "        ...,\n",
              "        [229, 232, 247],\n",
              "        [217, 220, 235],\n",
              "        [208, 211, 226]],\n",
              "\n",
              "       [[234, 238, 241],\n",
              "        [252, 255, 255],\n",
              "        [250, 253, 255],\n",
              "        ...,\n",
              "        [240, 242, 255],\n",
              "        [237, 239, 252],\n",
              "        [226, 228, 241]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[201, 198, 209],\n",
              "        [221, 218, 229],\n",
              "        [221, 215, 225],\n",
              "        ...,\n",
              "        [241, 234, 224],\n",
              "        [255, 250, 240],\n",
              "        [255, 251, 241]],\n",
              "\n",
              "       [[194, 191, 202],\n",
              "        [215, 212, 223],\n",
              "        [223, 217, 227],\n",
              "        ...,\n",
              "        [222, 215, 205],\n",
              "        [230, 223, 213],\n",
              "        [223, 216, 206]],\n",
              "\n",
              "       [[212, 209, 220],\n",
              "        [195, 192, 203],\n",
              "        [179, 173, 183],\n",
              "        ...,\n",
              "        [240, 233, 223],\n",
              "        [255, 248, 238],\n",
              "        [253, 246, 236]]], dtype=uint8)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrG-ykmIuOcj",
        "outputId": "3730fb7f-c715-4c75-96c3-8d8799446f84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXQpzyZt6Ui",
        "outputId": "605186d8-ce1a-4423-d2ea-f4a5f8add16a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "644"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcmg1WQuTIi",
        "outputId": "ae0ca33a-464c-46d1-bfe0-90e4f04c8cc5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "796"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI-7mKvJuixR",
        "outputId": "c6480206-266c-498b-f531-3841890aab38"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([132,  41, 246, 255], dtype=uint8)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMeBQA_suYnq",
        "outputId": "4d2eca6c-df95-4588-cfd6-ecfe8b76d3c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "KC2UWCMGuwz4"
      },
      "outputs": [],
      "source": [
        "palette = {0 : (60, 16, 152), # Building\n",
        "           1 : (132, 41, 246), # Land\n",
        "           2 : (110, 193, 228), # Road\n",
        "           3 : (254, 221, 58), # Vegetation\n",
        "           4 : (226, 169, 41), # Water\n",
        "           5 : (155, 155, 155)} # Unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XJGCusxYvIOi"
      },
      "outputs": [],
      "source": [
        "invert_palette = {v: k for k, v in palette.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "u2xjpP2VvUiY"
      },
      "outputs": [],
      "source": [
        "# сегментация нейронной сети в RGB изображение\n",
        "def convert_to_color(arr_2d, palette=palette):\n",
        "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
        "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = arr_2d == c\n",
        "        arr_3d[m] = i\n",
        "\n",
        "    return arr_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "7uyEDYdTv81I"
      },
      "outputs": [],
      "source": [
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8) # принадлежность каждого пикселя классу\n",
        "    min_distance = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.float32)+1000 # расстояние до ближайшего класса для пикселей\n",
        "    for c, i in palette.items():\n",
        "      distance = np.sum((arr_3d - np.array(c).reshape(1, 1, 3))**2, axis=-1)**(1/2) # ищем расстояние для каждого пикселя до проверяемого класса по евклиду рас-ие\n",
        "      condition = min_distance > distance # поиск элементов меньше min_distance\n",
        "      min_distance[condition] = distance[condition] # замена дистанции найденных элементов\n",
        "      arr_2d[condition] = i # замена класса найденных элементов\n",
        "\n",
        "    for c, i in palette.items():\n",
        "      m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "      arr_2d[m] = i\n",
        "\n",
        "    arr_2d = arr_2d.tolist()\n",
        "    for i in range(len(arr_2d)):\n",
        "      for j in range(len(arr_2d[0])):\n",
        "        label = [0, 0, 0, 0, 0, 0]\n",
        "        label[arr_2d[i][j]] = 1\n",
        "        arr_2d[i][j] = label\n",
        "    arr_2d = np.array(arr_2d)\n",
        "\n",
        "    return arr_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QRH5wFPIxysn"
      },
      "outputs": [],
      "source": [
        "X_train_pred = np.array(X_train).reshape([7, 644, 796, 3])/255\n",
        "X_test_pred = np.array(X_test).reshape([2, 644, 796, 3])/255\n",
        "Y_train_pred = []\n",
        "for i in range(len(Y_train)):\n",
        "  Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3]))\n",
        "Y_train_pred = np.array(Y_train_pred)\n",
        "Y_test_pred = []\n",
        "for i in range(len(Y_test)):\n",
        "  Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3]))\n",
        "Y_test_pred = np.array(Y_test_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "S6xEqOpzyK4m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "cl1UPcFfyhAs"
      },
      "outputs": [],
      "source": [
        "def unet_model(image_size, output_classes):\n",
        "\n",
        "    #Входной слой\n",
        "    input_layer = Input(shape=image_size + (3,))\n",
        "    conv_1 = Conv2D(64, 4,\n",
        "                                    activation=LeakyReLU(),\n",
        "                                    strides=2, padding='same',\n",
        "                                    kernel_initializer='glorot_normal',\n",
        "                                    use_bias=False)(input_layer)\n",
        "    #Сворачиваем\n",
        "    conv_1_1 = Conv2D(128, 4,\n",
        "                                      activation=LeakyReLU(),\n",
        "                                      strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer='glorot_normal',\n",
        "                                      use_bias=False)(conv_1)\n",
        "    batch_norm_1 = BatchNormalization()(conv_1_1)\n",
        "\n",
        "    #2\n",
        "    conv_2 = Conv2D(256, 4,\n",
        "                                    activation=LeakyReLU(),\n",
        "                                    strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer='glorot_normal',\n",
        "                                    use_bias=False)(batch_norm_1)\n",
        "    batch_norm_2 = BatchNormalization()(conv_2)\n",
        "\n",
        "    #3\n",
        "    conv_3 = Conv2D(512, 4,\n",
        "                                    activation=LeakyReLU(),\n",
        "                                    strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer='glorot_normal',\n",
        "                                    use_bias=False)(batch_norm_2)\n",
        "    batch_norm_3 = BatchNormalization()(conv_3)\n",
        "\n",
        "    #4\n",
        "    conv_4 = Conv2D(512, 4,\n",
        "                                    activation=LeakyReLU(),\n",
        "                                    strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer='glorot_normal',\n",
        "                                    use_bias=False)(batch_norm_3)\n",
        "    batch_norm_4 = BatchNormalization()(conv_4)\n",
        "\n",
        "    #5\n",
        "    conv_5 = Conv2D(512, 4,\n",
        "                                    activation=LeakyReLU(),\n",
        "                                    strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer='glorot_normal',\n",
        "                                    use_bias=False)(batch_norm_4)\n",
        "    batch_norm_5 = BatchNormalization()(conv_5)\n",
        "\n",
        "    #6\n",
        "    conv_6 = Conv2D(512, 4,\n",
        "                                    activation=LeakyReLU(),\n",
        "                                    strides=2,\n",
        "                                    padding='same',\n",
        "                                    kernel_initializer='glorot_normal',\n",
        "                                    use_bias=False)(batch_norm_5)\n",
        "      #Разворачиваем\n",
        "    #1\n",
        "    up_1 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
        "                                                                          padding='same',\n",
        "                                                                          kernel_initializer='glorot_normal',\n",
        "                                                                          use_bias=False)(conv_6), conv_5])\n",
        "    batch_up_1 = BatchNormalization()(up_1)\n",
        "\n",
        "    #Добавим Dropout от переобучения\n",
        "    batch_up_1 = Dropout(0.25)(batch_up_1)\n",
        "\n",
        "    #2\n",
        "    up_2 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
        "                                                                          padding='same',\n",
        "                                                                          kernel_initializer='glorot_normal',\n",
        "                                                                          use_bias=False)(batch_up_1), conv_4])\n",
        "    batch_up_2 = BatchNormalization()(up_2)\n",
        "    batch_up_2 = Dropout(0.25)(batch_up_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #3\n",
        "    up_3 = Concatenate()([Conv2DTranspose(512, 4, activation='relu', strides=2,\n",
        "                                                                          padding='same',\n",
        "                                                                          kernel_initializer='glorot_normal',\n",
        "                                                                          use_bias=False)(batch_up_2), conv_3])\n",
        "    batch_up_3 = BatchNormalization()(up_3)\n",
        "    batch_up_3 = Dropout(0.25)(batch_up_3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #4\n",
        "    up_4 = Concatenate()([Conv2DTranspose(256, 4, activation='relu', strides=2,\n",
        "                                                                          padding='same',\n",
        "                                                                          kernel_initializer='glorot_normal',\n",
        "                                                                          use_bias=False)(batch_up_3), conv_2])\n",
        "    batch_up_4 = BatchNormalization()(up_4)\n",
        "\n",
        "\n",
        "    #5\n",
        "    up_5 = Concatenate()([Conv2DTranspose(128, 4, activation='relu', strides=2,\n",
        "                                                                          padding='same',\n",
        "                                                                          kernel_initializer='glorot_normal',\n",
        "                                                                          use_bias=False)(batch_up_4), conv_1_1])\n",
        "    batch_up_5 = BatchNormalization()(up_5)\n",
        "\n",
        "\n",
        "    #6\n",
        "    up_6 = Concatenate()([Conv2DTranspose(64, 4, activation='relu', strides=2,\n",
        "                                                                          padding='same',\n",
        "                                                                          kernel_initializer='glorot_normal',\n",
        "                                                                          use_bias=False)(batch_up_5), conv_1])\n",
        "    batch_up_6 = BatchNormalization()(up_6)\n",
        "\n",
        "\n",
        "    #Выходной слой\n",
        "    output_layer = Conv2DTranspose(output_classes, 4, activation='sigmoid', strides=2,padding='same', kernel_initializer='glorot_normal')(batch_up_6)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "K4RZng-j1lSx"
      },
      "outputs": [],
      "source": [
        "from keras.losses import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fa1P0qSr1uAI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yAQmdfxZ1sLz"
      },
      "outputs": [],
      "source": [
        "#Функция для подсчёта DICE коэффициента\n",
        "def dice_coef(y_pred, y_true):\n",
        "    y_pred = tf.unstack(y_pred, axis=3)\n",
        "    y_true = tf.unstack(y_true, axis=3)\n",
        "    dice_summ = 0\n",
        "\n",
        "    for i, (a_y_pred, b_y_true) in enumerate(zip(y_pred, y_true)):\n",
        "        dice_calculate = (2 * tf.math.reduce_sum(a_y_pred * b_y_true) + 1) /\\\n",
        "         (tf.math.reduce_sum(a_y_pred + b_y_true) + 1)\n",
        "\n",
        "        dice_summ += dice_calculate\n",
        "    avg_dice = dice_summ/CLASSES\n",
        "    return avg_dice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "L9WoQKnD1bRr"
      },
      "outputs": [],
      "source": [
        "#Функция для подсчета DICE loss\n",
        "def dice_loss(y_pred, y_true):\n",
        "    d_loss = 1 - dice_coef(y_pred, y_true)\n",
        "    return d_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "j9lqcvoYzTAE"
      },
      "outputs": [],
      "source": [
        "# Binary crossentropy + 0.25 * DICE\n",
        "def dice_bce_loss(y_pred, y_true):\n",
        "    total_loss = 0.25 * dice_loss(y_pred, y_true) + keras.losses.binary_crossentropy(y_pred, y_true)\n",
        "    return total_loss"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
